{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\users\\44785\\anaconda3\\lib\\site-packages (1.19.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docx2pdf\n",
      "  Downloading docx2pdf-0.1.8-py3-none-any.whl (6.7 kB)\n",
      "Requirement already satisfied: importlib_metadata>=1.3.0 in c:\\users\\44785\\anaconda3\\lib\\site-packages (from docx2pdf) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=227 in c:\\users\\44785\\anaconda3\\lib\\site-packages (from docx2pdf) (227)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\44785\\anaconda3\\lib\\site-packages (from docx2pdf) (4.43.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\44785\\anaconda3\\lib\\site-packages (from importlib_metadata>=1.3.0->docx2pdf) (3.10.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\44785\\anaconda3\\lib\\site-packages (from importlib_metadata>=1.3.0->docx2pdf) (3.1.0)\n",
      "Installing collected packages: docx2pdf\n",
      "Successfully installed docx2pdf-0.1.8\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
      "Requirement already satisfied: lxml>=2.3.2 in c:\\users\\44785\\anaconda3\\lib\\site-packages (from python-docx) (4.6.3)\n",
      "Building wheels for collected packages: python-docx\n",
      "  Building wheel for python-docx (setup.py): started\n",
      "  Building wheel for python-docx (setup.py): finished with status 'done'\n",
      "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184600 sha256=62a20485498467ff6d33cb9d2e9684e1b6370cd1688c3e1d782883aed70f8a2e\n",
      "  Stored in directory: c:\\users\\44785\\appdata\\local\\pip\\cache\\wheels\\f6\\6f\\b9\\d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
      "Successfully built python-docx\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-0.8.11\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DirEntry '12+ (2).pdf'>\n",
      "12+ (2).pdf\n",
      "---------------------------------------------------------------------------------------------------        Professional Summary:                                             ●  Around 12+ Years of IT experience in PL/SQL, Mainframes and Data Science  technologies in Retail, Banking and Healthcare domains  ●  Around 4+ years of experience as Data Scientist with proven expertise in Machine  Learning Algorithms, Deep Learning concepts such as ANN, CNN, RNN and python with  libraries such as SKLearn, NumPy, Pandas, Matplotlib, Keras and Tensor Flow.  ●  Around 1+ year of experience in Pentaho for building files via access to database.  ●  Around 8+ years of experience in Mainframes platform with expertise in COBOL, JCL,  VSAM, SAS, DB2 in both development and Support roles as well as PL-SQL and Oracle  Database  ●  Strong proficiency in application development & quality-driven methodologies.  ●  Expertise in full SDLC implementation as a key resource in requirement gathering,  estimation, design, coding and testing in both Waterfall and Agile Methodology.   ●  Involved in sprint planning, creation of user stories, assessment of story points, Agile  retrospective meeting.  ●  Extensively used JIRA tool for tracking user stories and effort  ●  Strong Leadership skills and rated as a very capable resource in managing team  effectively.  ●  Excellent communication and presentation skills, self-starter, quick learner & team          player    Technical Skill Set:    Programming Languages:   Python, Machine Learning (NumPy, Pandas, Matplotlib), Deep Neural Networks (Keras, Tensor  Flow), Convolutional Neural Networks, SKlearn Libraries, SPARK Framework, SCALA basics,  COBOL, SAS, JCL, VSAM, SQL/PLSQL    TOOLS:   Anaconda, Jupiter Notebook, Pentaho, JIRA, GitHub, IBM Personal Communication tools like -  IBM File Manager, CA-7, SDSF, SAR, IBM File manager, QMF, SPUFI, SUPERC, Endevor,  Change Man, ITSM Change Management Tool,     Data Base:  DB2, ORACLE    Professional Work Experience:    ➢ Started working in JP Morgan Chase as Senior Application Lead Developer from Oct 2015  till date.  ➢ Worked as Principle Software Engineer in TESCO HSC from February 2011 till Oct 2015.  ➢ Worked as Software Engineer in Fidelity India Pvt Ltd from September 2010 till Feb 2011.  ➢ Worked as a Lead coordinator in IBM India Pvt LTD from Sep 2009 till August 2010.  ➢ Worked as Developer in IBM India Pvt Ltd from August 2006 Till August 2009.    Certifications and Achievements:    ➢ Won as a runner in ML Theme in TechGig competition.  ➢ Completed Data science masters in ACADGILD.  ➢ IBM Certified DB2 Fundamentals.  ➢ SAS certified base programmer.  ➢ Certified PAHM (Professional Academy for Healthcare Management) in Year 2007.  ➢ WellPoint Achievement award for outstanding performance in GL project.  ➢ Received Value award for smooth and successful closure for Christmas.  ➢ Involved in CMMI Level 5 recertification program as a Lead and participated in interview  with CMMI.    Assignment Summary:      Project # 1    Project Name : Loan Grader                                                             Role  : Data Scientist  Client     : JPMC  Duration         : Oct 2016 to Sept 2017  Environment : Python, SKLearn Libraries, Data Visualisation Thru Matplotlib/Seaborn,  Machine Learning Algorithms    Description: Predict the rating of all customers in order to decide whether he/she is a  potential customer to be considered by taking the history of the transactional data which  includes banking, card transactions, loans.    Responsibilities:  ●  Requirement discussions with the clients and also coordinating with Operations team to       understand the manual work around done by the team.  ●  Review the estimates for work items, help the team with impact analysis and participate in  estimation justification meetings with the clients.  ●  Identifying the points from where we need to get data sources and data consolidation  process.  ●  Involved in Data Pre-processing Techniques such as data cleaning, visualizing the data,  identifying outliers and making data ready for Machine Learning Techniques.  ●  Machine Learning Algorithms Evaluation.  ●  Analyze the results of all algorithm outcomes and deciding the best one  ●  Model Deployment process once signoff is in place.      Project # 2    Project Name : Document Index Processing thru NLP                        Role   : Data Scientist  Duration  : Aug 2017 to Dec 2018  Client     : JPMC  Environment : Python, SKLearn Libraries, Data Visualisation Thru Matplotlib/Seaborn, NLP,  Machine Learning Algorithms    Description: Operations Team manually open several documents as part of their monthly  process and decide which type of billing should be done. They take the figures from the  respective documents and proceed with the billing process. Using NLP document indexing  automated the process of document identification and this has resulted in reducing lot of FTE  effort.    Responsibilities:  ●  Numerous discussions with Operations team and understand the process of work done  ●  Engaging with clients and discuss on way of approach for automating the process.  ●  Review the estimates for work items, help the team with impact analysis and participate in  estimation justification meetings with the clients.  ●  Create a platform to get all the documents at one place which is used as an input for  Machine Learning Algorithm  ●  Data Pre-processing Techniques such as data cleaning, visualizing the data, identifying  outliers and making data ready for Machine Learning Techniques.  ●  Measure the performance of the algorithms applied and choosing the best one.  ●  Model deployment.  Project # 3    Project Name : Mini project on Customer behavior with change in rates  Duration  : 2 months                                                                 Role   : Data Scientist  Client     : JPMC                         Environment : Python, SKLearn Libraries, Data Visualisation Thru Matplotlib/Seaborn,  Machine Learning Algorithms    Description:  As part of this project, prediction of behavior of a customer with the revision of  rates as quick grasp for end business users.     Responsibilities:  ●  Review the estimates for work items, help the team with impact analysis and participate in  estimation justification meetings with the clients.  ●  Involved in Data Pre-processing Techniques such as data cleaning, visualizing the data,  identifying outliers and making data ready for Machine Learning Techniques.  ●  Model performance evaluation and presentation to the business users.      Project # 4    Project Name : Prediction of database spikes                                      Role: Data Scientist  Duration  : 2 months  Client     : JPMC  Environment : Python, SKLearn Libraries, Data Visualisation Thru Matplotlib/Seaborn,  Machine Learning Algorithms    Description: As part of this project, prediction of database spikes for current year based on  last 5 years of data.    Responsibilities:  ●  Review the estimates for work items, help the team with impact analysis and participate in  estimation justification meetings with the clients.  ●  Involved in Data Pre-processing Techniques such as data cleaning, visualizing the data,  identifying outliers and making data ready for Machine Learning Techniques.  ●  Model performance evaluation and presentation to the business users.      Project # 5    Project Name : Consolidated Billing system                       Role: Application Lead Developer  Duration  : Oct 2015 to Sept 2016  Client     : JPMC  Environment : Mainframes-COBOL, JCL, DB2,VSAM,CICS,SAS    Description: CBS handles all Regular Trades, Fixed Billing, Custodian Billing on a daily basis  and monthly basis. Calculates commission and execution charges for all the settled trades.  Creates end to end reports and Invoices for all the customers.    Responsibilities:  ●  Involve in all phases of software development like Analysis, design, coding, testing for  development and enhancement work requests (work orders greater than 500 hours).  ●  Participation in requirements gathering meeting with clients.  ●  Review the estimates for work items, help the team with impact analysis and participate in  estimation justification meetings with the clients.  ●  Review of all the work artifacts from the team.  ●  Providing the test support and fixing all the defects raised.  ●  Implementing the changes in production system.  ●  Supporting and Monitoring Production batches.      Project # 6    Project Name    : SAFE, CASH REPORTS                        Role   : Principle Software Engineer   Duration     : Feb 2011-Oct 2015  Client                 : TESCO  Environment    : Mainframe technologies (COBOL, JCL, VSAM, DB2, SAS, ORACLE, PL-SQL)    Description: SAFE is part of IT-Finance. Settlement processing is handled by the Safe  system. The purpose of settlement is to confirm the successful processing of a transaction and  to obtain payment from the bank. SAFE takes care of settlement. Processes batch Settlement  Files to our Acquiring Banks and hold the data for every transaction processed online for 60  days. The files are sent to different banks like RBS, NATWEST, HSBC, AMEX, COMPOWER  (ATOS) based on the card type. The banks will process the data and pay funds directly into  our Tesco bank account.    Cash Reports is a reconciliation system where all the tender related details are recorded and  stored in the oracle database tables. All the records will be loaded into Accurate SQL server  database and reconciled using FISERV tool named as Accurate. All the reconciled data and  data cleared by business user will be reported to General Ledger.    Responsibilities:  ●  Involve in all phases of software development like Analysis, design, coding, testing for  development and enhancement work requests (work orders greater than 500 hours).  ●  Participation in requirements gathering meeting with clients.  ●  Preparing various reports for client status meeting.  ●  Review the estimates for work items, help the team with impact analysis and participate in  estimation justification meetings with the clients.  ●  Participate in all AGILE SCRUM meetings and update the status of work parcel.  ●  Review of all the work artifacts from the team.  ●  Providing the test support and fixing all the defects raised.  ●  Implementing the changes in production system.  ●  Supporting and Monitoring Production batches.  ●  Provide maintenance support for the application which includes all the housekeeping Jobs.      Project # 7    Project Name : Retirement Plans                                               Role   : Software Engineer  Duration  : Sep 2010 – Feb 2011  Client     :  Fidelity  Company  : Fidelity India Pvt Ltd  Environment : Mainframe technologies (COBOL, JCL, VSAM, SAS, DB2)    Description:  This project is mainly designed to provide benefits to employees for tax  exemption and to save money till retirement. Selection of the plan choice is given purely to  the employee and employer will share the money based on the plan selection. So as part of  this project, we need to pull the reports as per the customer’s demand and sent to the clients  at the desired deadline without any delay.    Responsibilities:  ●  Deliver the reports requested by End users in time without any delay.  ●  Taking project related calls and interacting with clients and end users directly.  ●  Mentoring new joiners in the project.  ●  There are few challenges where in there is a requirement from end users to create the  reports in a customized which requires logical change in the program. Able to change the  code in a less stipulated time and deliver the reports to the users at the right time without  any delay.  ●  Automated few reports which reduced manual effort.      Project # 8    Project Name      : General Ledger Project                            Role    : Application Developer  Duration       : April 09 – Aug 10  Client                   :  WellPoint  Company       : IBM India Pvt Ltd  Environment      : Mainframe technologies (COBOL, JCL, VSAM, SAS, DB2)    Description:  This project is to post the Administrative services only Group’s billed and  unbilled claim level activity to the general ledger. This involves high risk that involves  developing complex code, rigorous Unit Testing and Integration Testing. Helped customer in  coming up with the requirements by suggesting easiest way to proceed. Worked closely with  the Customer and came up with neat schedule and plan for unit testing and integration testing  to avoid the risk. Also delivered the code with high quality 1 week earlier than planned date to  dependent system and delivered the project without any business impact to Customer.  Received very high appreciation from the Customer, Onsite BAM and Delivery Manager. Played  key role and lead the project team in Analysis, Design, Unit testing, Test planning, System  testing, Regression setup and support, Pre Implementation support, Implementation support.    Responsibilities:  ●  Responsible for successfully implementing the project without any issues.  ●  Successfully handled big releases of the project which helped our client in getting  compliance certificate without any Non-compliance.  ●  Follow complete SDLC cycle whenever application upgrade takes place – used   Waterfall  methodology depending on the complexity and flexibility of the requirement.  ●  Have successfully deployed project which gave me an exposure to work on all of these  phases - Requirements Gathering, Analysis, Estimation, Designing, Development, and  Testing till Implementation. Used all the standards followed in our organization (e.g. OPAL  process and templates).  ●  Key participant in Quality process for the project  ●  Submitting Project Metrics and participating in all Quality processes/audits, project health  reviews.  ●  Worked on Rational portfolio manager.  ●  Taking project related calls and interacting with clients and end users directly.  ●  Mentoring new joiners in the project.   ●  There was a challenge while implementing the project since it involves feeds across  applications. I am able to coordinate across the teams, organize meetings and drill down  the solution in very quick turnaround of time.  ●  Supporting and Monitoring Production batches.       Project # 9    Project Name   :  MCS Prompt Pay Project                              Role   : Application Developer  Duration    :  July 2008 – December 2008  Client              :  WellPoint  Company   :  IBM India Pvt Ltd  Environment  :   Mainframe technologies (COBOL, JCL, VSAM, SAS, DB2)    Description:    New York state mandate to charge all the groups for late fee payment and hence as part of  this project Prompt pay amount need to be included as an additional field in the current logic  and charge the group this late fee payment. Worked on new design with several modules  being developed for this project. As well on Customer’s demand created few reports as well  which will help in auditing purposes.    Responsibilities:  ●  Responsible for successfully implementing the project without any issues.  ●  Responsible for successfully implementing the project without any issues.  ●  Follow complete SDLC cycle whenever application upgrade takes place  ●  Used   Waterfall methodology depending on the complexity and flexibility of the  requirement.  ●  Have successfully deployed project which gave me an exposure to work on all of these  phases Requirements Gathering, Analysis, Estimation, Designing, Development, and  Testing till Implementation. Used all the standards followed in our organization (e.g. OPAL  process and templates).  ●  Analyzing the Functional inputs and estimating the size of the project.  ●  Supporting and monitoring production batches.  ●  Resolving defects and User queries in production within SLA.      Project  # 10    Project Name  :  NPI Contingency Project (National Provider Identifier)  Duration          :  July 2007 – December 2007                       Client             : WellPoint                        Role  : Application Developer  Company         : IBM India Pvt Ltd  Environment  : Mainframe technologies (COBOL, JCL, VSAM, SAS, DB2)    Description:    This project implemented as a contingency to the original NPI project due to US federal  mandate requirements allowing the providers the flexibility to send the claims with both  Empire provider number and Federal NPI as well. Due to high quality work delivered got  appreciations from high level authority.  Responsibilities:  ●  Worked on development requests which involved code changes.  ●  Analyzing the Functional inputs and estimating the size of the project.  ●  Perform unit testing once development and design (technical document) is completed.  ●  Supporting and monitoring production batches.  ●  Resolving defects and User queries in production within SLA.  ●  Responsible for successfully implementing the project without any issues.      Education Summary:    ➢ Corporate Post Graduate Diploma from SYMBIOSIS with 71% during 2007-2009.  ➢ Bachelor of Technology from Jawaharlal Nehru Technological University, Hyderabad with  74.5% in year 2006.  ➢ 10+2 from S.V.S.R Junior College with 95.4% in year 2002        \n",
      "<DirEntry '12+.pdf'>\n",
      "12+.pdf\n",
      "          SANDEEP.DASC1@GMAI L.COM  HTTPS://GITHUB.COM/S ANDEEPDASC1  WWW.KAGGLE.COM/SA NDEEPDASC1  WWW.LINKEDIN.COM/IN /PULAVARTHY-S- 321A92152/    SP  OBJECTIVE  Apassionatedatascientisthav ingexperienceinpredictive modelling,dataprocessing,a nddataminingalgorithmstoso lvechallengingbusinesspro blems.StrongbackgroundinP ythonandknowledgeofvariou stypesofmachinelearning  techniques.  SOFTWARE TOOLS  Jupyter  Anaconda  Spyder  CODING SKILLS  Core Python  NumPy  Pandas  Scipy  Matplotlib    EXPERIENCE  LEAD ENGINEER •TCS• JAN/2017 – TILL DATE  •  Understand the requirements and formulate problem  statements.  •  Acquisition and analysis of data.  •  Analyze data sets to provide insights to experts from  various domains.  •  Building statistical modeling and applying various  machine learning techniques.  •  Use of analytics for automation and enhancement in the  field of aerospace industry eg. - predictive maintenance  using machine learning  •  Data Understanding and process formation from clients.  •  Extensive hands-on with regression and classification  techniques.  •  Building baseline models for the requirements with  necessary data preparation.    PROJECT LEAD• SEMCONINDIA PVT LTD • NOV/2010 –JAN/2017    Project 1: After analyzing datasetsfrom various engines built  predictive models for high impact Aero-Engine components.  This model has not only consistently predicted the failure of  components, but also helped reduce the downtime of aircraft  in the field.  Project 2: Built an integrated spare parts forecasting model  for a dealer network of a major OEM. The solution improved  traditional forecasting models with the real-time demandfor  the spare parts collected from asset performance in the field    SP  SANDEEP PULABARTH  LEAD ENGINEER @TCS | +91-8722274646              SANDEEP.DASC1@GMAI L.COM  HTTPS://GITHUB.COM/S ANDEEPDASC1  WWW.KAGGLE.COM/SA NDEEPDASC1  WWW.LINKEDIN.COM/IN /PULAVARTHY-S- 321A92152/  2  MACHINE LEARNING  Exposure to   Random Forest,  Decision tree,  KNNs,   Adaboost  XGBoost  Linear Regression  Logistic Regression  KMeans  OTHER SKILLS  Statistics  Hive  SQL  Unigraphics NX  Teamcenter Engineering  PLM/PDM Tools        Mechanical Projects  Domain: Steam Turbine, Turbomachinery  Client:    Siemens –Finspong, Sweden  Tool:      NX6, Catia V5, Teamcenter & Pulse  Inputs:   CADDS5 and Turbine 2D Layout.      Responsible for 5 Engineers team working for Siemens steam  Turbine-Finspong on Migration and Design & Development.  Involved in Migration of CADDS5 drawings to NX and creating  Manufacturing drawings for various steam turbine components  like casings, Inlet and exhaust bearing, Rotors, diaphragm  carriers, Labyrinth seals, Valves, Inlet volutes from Iges, Exhaust  casings from 2D layouts    Project: Design and Migration of Steam turbine components of  SST700/900 from CADDS5 to NXAnd creating Manufacturing  drawings from provided Turbine Layouts    Roles & Responsibilities:     1. Trained Engineers on NX, Siemens workflow process,  Steamturbine components, Team Centre & Pulse  2. Responsible for gathering inputs from Siemens and  discussing with HG responsible on improvements and  Technical issues before starting work.  3. Work planning and allocating tasks based on skill sets of  the engineers.  4. Supporting Team in technical and design issues.   5. Responsible for quality and on-time delivery.  6. Worked on Design & Detailing of various steam turbine  components like casings, bearings, rotors, Internal pipes  SP  SANDEEP PULABARTH  LEAD ENGINEER @TCS | +91-8722274646              SANDEEP.DASC1@GMAI L.COM  HTTPS://GITHUB.COM/S ANDEEPDASC1  WWW.KAGGLE.COM/SA NDEEPDASC1  WWW.LINKEDIN.COM/IN /PULAVARTHY-S- 321A92152/  3  & conn., Exhaust casings, Inlet volute etc.  7. Prepare relevant design and layouts using NX in  accordance with appropriate standards and design.  8. Preparing Bill of material specifications for various steam  turbine components and creating new structures.  9. Set up new process and checklist to ensure quality output  to the client.  10. Reviewing the drawings in customer data base and  approving them to next level.    SR ENGINEER •INFOTECH (PRESENTLY CYIENT) • JUN/2008 –  NOV/2010    Domain: Aircraft Engine, Aerospace  Client: Pratt & Whitney  Role: Design Engineer    About P&W - Pratt & Whitney was developing a new engine  configuration having a geared technology for its Next  generation products, PW1000G. According to Pratt & Whitney in  engine configuration a new bearing (#6) is to be added. The  legacy engines of Pratt consist of only 5 number of bearing  compartments. #6 bearing compartment is newly added in  PW1000g. Our team was responsible for design of Squirrel  cage, Jumper tube, Spacer, End cap and Rear Nozzle. The  components should satisfy both Design Criteria and also  manufacturing feasibility.    Projects involved were    1. Design of #6th Bearing Compartment parts/ PW1000G  MRJ  SP  SANDEEP PULABARTH  LEAD ENGINEER @TCS | +91-8722274646              SANDEEP.DASC1@GMAI L.COM  HTTPS://GITHUB.COM/S ANDEEPDASC1  WWW.KAGGLE.COM/SA NDEEPDASC1  WWW.LINKEDIN.COM/IN /PULAVARTHY-S- 321A92152/  4  2. Design of Squirrel cage & Detailing  3. Design of Spacer & Detailing  4.  Design #4th Bearing Compartment parts/ PW1000G MRJ    5. Design of Air Deflector & Detailing  6. Sector Cut Models of all Bearing Compartment parts/  PW1000G MRJ  7. Design #1 Bearing Compartment parts/ FT4000  .  ENGINEER • KABRA EXTRUSIONTECHNIK LTD•MAY/2006 – JUN/2008    •  I am involved as a design engineer in processing regular  work order along with upgrading of existing extrusion  machinery.    My role also demands   •  Design, modelling and drafting of plastic extrusion  Machines.  •  Provided total plant layout for assembly purpose.  •  Prepare assembly drawings for assembly purpose.  •  Reverse engineering of the plastic extrusion machinery  critical parts.  •  Conversion of collaborator’s Die head drawing from  ASME standards to ISO standards.    •  Process all Tape plant work orders.    EDUCATION  BACHELOROF MECHANICAL ENGINEERING• 2006 • GANDHI  SP  SANDEEP PULABARTH  LEAD ENGINEER @TCS | +91-8722274646              SANDEEP.DASC1@GMAI L.COM  HTTPS://GITHUB.COM/S ANDEEPDASC1  WWW.KAGGLE.COM/SA NDEEPDASC1  WWW.LINKEDIN.COM/IN /PULAVARTHY-S- 321A92152/  5  INSTITUE OF ENGINEERING AND TECHNOLOGY,GUNUPUR  You might want to include your GPA and a summary of relevant  coursework, awards, and honors.  AWARDS  •  Spot Appreciation Award - 12th May 2016  •  Certiﬁcate of Appreciation - 22nd July 2015  •  Spot Appreciation Award - 29th May 2014  •  Outstanding team performance – November 2008    \n",
      "<DirEntry '15+ (1).pdf'>\n",
      "15+ (1).pdf\n",
      "                                                                                      Experience summary  1.  A Professional  with about 15 years of experience in Python Machine learning, Deep learning  Data science , Big data, Mobile applications , data staging and testing, web application  development and testing until production deployment and support with an insight into IBM  Cloud infrastructure solutions, Finance, Life and General Insurance, Telecom and HRMS  database payroll domains.  2.  Data science professional with experience in all stages of data processing and insights delivery.  3.  To understand business use cases and requirements from clients and convert them into a well  articulated problem statement and explain to the project teams.  4.  Analyze unorganized data, assessing quality, cleansing, structuring for management  review and design accurate and scalable prediction algorithms.  5.  To identify relevant data sets required to develop predictive models for solving internal and  external business problems.  6.  To explore data sets and identify data transformation and data mining needs for targeted  insurance applications.  7.  To develop algorithms and predictive models to derive analysis and business value from data  sets through classification, clustering and regression.  8.  To provide the mentorship required for the other team members of the team.  9.  Identify the use cases and help the teams to implement, which might help organization  business development.  10. To define and develop the programs for data collection, modelling and reporting the  operational performance.  11. Responsible for Budget planning, Schedule planning and resource profiling for all the project  phases.  12. To lead and support various adhoc projects, as needed, in support of organizations business  strategy.  Skills and Knowledge areas  Category  Software/  Tool/Technology  Proficiency  Experience in years  Data science  Data cleansing  Data mining  Data modelling  Data analysis      Python Algorithms  using Machine Learning  Tensor flow  Pandas   Numpy   SCIKIT learn  Intermediate  4 + years  Machine learning  Linear and Logistic   Regression,  Classification- KNN,   Naive Bayes.  Clustering – K - means  Supervised Learning,   Unsupervised learning   Over fitting,   Parametric and  non-Parametric   modelling  Deep Learning  CNN,RNN    K means, SVM  LSTM,Tensor Flow          Intermediate  3+ Years  Operating Systems  Windows 98, 2000 server,  Expert  14+ years  XP, Windows 8,10,  Android, IOS  Office Tools  MS office applications  Expert  14+years  Languages  C , Java, VB, PYTHON  Intermediate  4+ years  Pl/SQL  SQL  Intermediate  2+ years  Verification tools  ALM(Quality centre  8.0,8.2)  Selenium 2.0 Web drivers  (Java)  QTP 8.0,8.2, (UFT 12.5)    Working  Knowledge  5+ years  Achievements    Have been recognised for contributions of developing an automated chatbot concept for  claims part as cost saving project for an European Insurance Giant(TRYG)    Have received highest level customer appreciations for successfully delivering the Regular  Contribution ISAs insurance and Work save Pension Trust (Master Trust) project product to the  market for Legal and general client within TCS.    Demonstrated excellent working skills and performed in projects which are very critical and     received appreciations from customer (Legal and General united kingdom)    Awarded with best performance in the form of spot awards from Fidelity in 2007-2008.    Recognized as one of the best associates for onsite client Coordination.  Professional Experience summary  Currently associated as Delivery project executive with IBM India Pvt limited since April 2017  Previously associated with Tata consultancy services India Ltd (Jun 2008 – March 2017)    Associate consultant from April 2012 - March 2017    IT Analyst             from Jun 008 – April 2012   Previously associated as Test Engineer with Fidelity Business Services India Pvt Ltd, from Feb 2006 - May  2008  Previously Associated as Software Engineer with Verizon Data Services India (Chennai), from May 2005 -  Feb 2006  Previously Associated as Technical Support Engineer with Dell International Services Pvt Ltd from Nov  2002 – Apr 2005  Project Summary  1  IBM India Pvt Limited  Client                         APAC clients (711, NESA, Hannon, IAG insurance)  Project Title / Name      Cloud solutions and Watson data analysis  Project Duration                 April 2017 – till date.  Project Location       Bangalore.  Team Size         15  Project Description:  This project is to rebuild the existing platforms and infrastructure which are legacy in nature into ne  cloud based and big data based platforms to enable the cost efficiency using the Big Data  technology implementations.  Classification of Operational data in CSV format and unorganized data using Liner regression and K  means and Naive bayes algorithms. and also coming up with both linear regression and logistic  regression model for reading and converting the Incidents data reported across Asia pacific clients.  Prediction of heat maps and forecasting the future data based on the heat maps produced and  coming up with the solutions to fix the infrastructure issues.  Roles and responsibilities    Have been playing a role of Delivery Project executive, taking care of overall solutions  delivery for Asia pacific clients mentioned above.    Responsible for identifying the data sets required to come up with predictive models  for providing solutions for both internal and external business problems.    Used IBM Watson for the data analysis and standardization and to come up with heat  maps.    Involved in the trend prediction and analysis which led to quality solutions and  retaining high valued potential customers.    Enabled the project to run in the agile delivery model.  Technology stack:    Python, IBM Watson, Linear regression classification and clustering, Predictive  modelling, Heat maps  2  Tata consultancy services  Client                         PNC financial services (United States of America)  Project Title / Name      Lending transformation for mortgages  Project Duration                 August 2016 – January 2017  Project Location       Bangalore.  Team Size         10  Project Description:   This project was a major platform change and upgrade of a huge mortgage loan processing  application from old technology to new technology.PNC Mortgage loans application had several  modules such as Origination, Pre-underwriting, underwriting, processing, funding and closing.   This was a huge database of data of customers who would apply for Mortgage loans had to undergo  screening through Data cleansing act based on various features and parameters such as Credit history,  Medical history, financial statuses, and claims in any other insurances. This was basically collecting all  the information of customers through the origination process filtering them based on the eligibility  criteria to pass it through Pre underwriting and underwriting processes. Later the eligibility of the  customers is derived based on the above features through regression algorithms and modelling.              Roles and responsibilities    Have worked as programme manager involved in gathering the requirements and  understanding the business use cases from clients and convert them into a well  defined problem statement and explain it to the development team.    Responsible for identifying the data sets required to come up with predictive models  for providing solutions for both internal and external business problems.    Responsible for supervising the Data cleansing, Validation, data classifications and  data modelling activities.    To develop algorithms in python like KNN, K – Means linear regression and SVM.as part  of data analysis.   Technology stack:    Python, Numpy, Pandas, Matplotlib, ALM,   3  Tata consultancy services  Client                         TRYG (Copenhagen, Denmark)  Project Title / Name      Price Premium conversion  Project Duration                 February 2013 – August 2015  Project Location       (Copenhagen, Denmark)  Team Size         12  Project Description:   Main frame suite is called as Price Conversion project involves conversion of existing Products from old  platforms to the new platforms, eventually converting all the existing customers on the old platform to  new platform which includes Neutralization/Rise/Fall of premiums Based on certain Tariff parameters.  This Program mainly involves in converting the General Insurance products such as Household, Building,  Personal car, Commercial Car, Holiday house, Pet Insurance, Horse insurances, Workmen’s  compensation, Accident Insurance and Healthcare related insurances.  This project requirement of analysis of customer involved different sets of data analysis ranging from  data related to gaining customer insight by collecting information and arriving at the premium  calculations in the initial steps and also determining the Fraud based on the claims data associated  with each customer and multiple products mentioned above related to each customer.  Roles and responsibilities    Have worked as team lead involved in gathering the requirements and understanding  the business use cases from clients and convert them into a well defined problem  statement and explain it to the development team.    Responsible for identifying the data sets required to come up with predictive models  for providing solutions for both internal and external business problems.    Responsible for supervising the Data cleansing, Validation, data classifications and  data modelling activities.    Claims processing automation using chatbot for customer direct calls.    To develop algorithms in python like linear regression and SVM.as part of data analysis.   Technology stack:    Python, Numpy, Pandas, Matplotlib, ALM, Mainframes legacy systems.    4  Tata consultancy services  Client Name                           Legal and General (United Kingdom)  Project Title / Name      Auto enrolment for Pensions, Choice *Opt out  Project Duration       July 2011 – January 2013.  Project Location       Bangalore – United Kingdom  Team Size        20  Technology Stack   Mainframes, Visual basics, Java, HPS appbuilder, SOA  Services, Windows Xp, Unix, Quick test pro 8.0, Quality center ,  Roles and responsibilities    Business Coordinator    Requirement Analysis and Business workflow analysis.    Software design, development and Maintenance.    Project Management and strategy creation.    4Budget Planning, Schedule planning and Resource profiling for the project phases    Coordination with the Business and Requirement team for understanding the new  requirements and enhancements.  Project Description  Auto-enrolment will mean workers being automatically enrolled into their employer's qualifying pension  scheme without any active decision on their part. At present, many workers fail to take up valuable  pension benefits because they do not make an application to join their employer's scheme. Auto- enrolment is meant to overcome this.  From 1 October 2012 (subject to the employer's own introduction date), all eligible workers will have to  be auto-enrolled into a qualifying pension scheme.  Employers can choose the qualifying scheme they  use, which could include NEST (the National Employment Savings Trust).  Each qualifying scheme must  meet minimum standards in respect of the benefits it provides or the amount of contributions paid to it.   The scheme must also provide auto-enrolment for all eligible workers and for all new workers when they  become eligible.  5  Tata consultancy services    Client Name                                                Legal and General (United Kingdom), IBM  Project Title / Name      Data Center Migration, Windows Upgrade  Project Duration       July 2011 – June 2013.  Project Location       United Kingdom.  Team Size        20  Role          Business Coordinator  Technology Stack   Quality center, Mainframes, HPS appbuilder, Java, SOA  Services, Windows Xp, and UNIX.       6  Tata consultancy services  Client Name        Legal and General (United Kingdom)  Project Title / Name  Work save Pension Trust(Company pension scheme) and work  save Funds  Project Duration       NOV 2010 – Jun 20111  Project Location         Bangalore.  Team Size        6  Role          Team Lead  Technology Stack  Mainframes, HPS appbuilder, Java, SOA Services, Ecomm,  web sphere applications Java, Windows Xp, UNIX.  ____________________________________________________________________________________________________  7  Tata consultancy services    Client Name        Legal and General (United Kingdom)  Project Title / Name      Portfolio Regular Investment Plan(Qualifying savings Plan)  Project Duration       Apr 2010 – October 2010.  Project Location       Bangalore.  Team Size        5  Role          Business Coordinator  Technology stack  Mainframes,  HPS  appbuilder,  Windows  Xp,  UNIX.  Enhancement testing, Regression Testing,   ____________________________________________________________________________________________________  8  Tata consultancy services  Client Name        Legal and General (United Kingdom).  Project Title / Name      Regular Contribution individual savings account  Project Duration        Sep 2009 -July2010.  Project Location       Bangalore.  Team Size        10  Role          Team lead   Technology stack  Mainframes, HPS appbuilder, Java, SOA Services, Ecomm,  web sphere applications Java, Windows Xp, UNIX.         9  Tata consultancy services  Client Name        Legal and General (United Kingdom).  Project Title / Name      Pensions and Bonds (Personal, Stake holder pension)  Project Duration       July 2008 to Sep 2009.  Project Location       Bangalore.  Team Size        6  Role          Team Member  Technology stack      Mainframes,HPS appbuilder,  Ecomm,  ____________________________________________________________________________________________________  10  Fidelity Investments PVT LTD  Client Name  ABB, Bank of America, Agilent, Fidelity, Knight Rider, First  American Corporation, Analog Devices, Visitor, BASF.  Project Title / Name      Oracle Human Resource Management Systems.(HR Payroll)  Project Duration       Feb 2006 to May 2008.  Project Location       Bangalore.  Team Size        10  Role          Team Member  Technology stack      Java, Oracle apps, Oracle 9I, SQL, Windows Xp, and UNIX.QTP  Project Description  Oracle HRMS payroll is a management system which can help you to control workforce Costs and  ensure that the entire workforce is being paid on time and according to company’s customized  compensation rules and fully integrated with Oracle Financials. Oracle Payroll is based on a global  HRMS engine with country-specific localization extensions to better manage global HR operations.  The HR Payroll provides a service that helps employees, managers and Human resource professionals  make more informed decisions. These include:    HR Administration and employee data maintenance.    Compensation administration.    Payroll administration and tax filling.    Eworkplace and netbenifits are the web-based service model which empowers HR  Professionals, Managers and employees of our client companies to locate and update  information themselves like:    Recruitment  and  Staffing.  /  Employee  Administration.  /  Payroll.  /  Benefits  Administration.        ____________________________________________________________________________________________________  11  Fidelity Investments PVT LTD    Client Name        Bank of America, Fidelity, BASF Corporation  Project Title / Name      Performance management systems                                           Project Duration       Feb 2006 to May 2008.  Project Location       Bangalore  Team Size        5  Role          Team Member  Technology Stack  Java, Oracle apps, Oracle 9I, Windows, Unix, Quick test pro.  Project Description  Performance management system is an application, to plan the goals of an employee of a company  on annual basis, it consists of fixing the employee ratings, developmental skills, list of competencies  required for an employee under a manager. The complete project cycle involves flow between the  employee, manager and H.R administrator. The Performance plans created by the employee have to  be approved by managers and H.R. administrators in order to complete the performance Plan.  _____________________________________________________________________________________________  12  Verizon PVT LTD  Client Name        VERIZON  Project Title / Name      Local and National Transparent LAN services.  Project Duration       June 2005 to Feb 2006  Project Location       Chennai  Team Size        8  Role          Team Member  Technology stack      J2EE, JSP, Web Sphere, Oracle, Windows    Project Description    The Products like Local TLS and National TLS are the data Transfer Layer 2 products offered by Verizon.  The products sales and product configuration is automated through software. The Enterprise customer  can login to the portal and be able to select the products and configurations.    __________________________________________________________________________________________________          13  Verizon PVT LTD  Client Name        VERIZON  Project Title / Name      LOCAL FAST PACKET and IPVPN  Project Duration       May 2005 to Feb 2006  Project Location       Chennai  Team Size        8  Role          Team Member  Technology Used      J2EE, JSP, Web Sphere, Oracle, Windows  Project Description    The Products like Local ATM, Local Frame Relay, IPVPN are the data Transfer Layer 2 & 3 products  offered by Verizon. The products sales and product configuration is automated through software. The  Enterprise customer can login to the portal and be able to select the products and configurations.  14  Dell International PVT LTD  Client Name        United states and Canada Dell Customers  Project Title / Name      united States /Canada Technical Support  Project Duration       Nov 2002 – Apr 2005  Project Location       Bangalore  Team Size        15  Role          Team Member  Technology Used      Dell serv andVoip    Education Summary  Masters in European construction project management             2015-2016                                                                                University of Cantabria (Spain)  Bachelor of Technology (Civil)              1996-2000  Bangalore University  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DirEntry '15+.pdf'>\n",
      "15+.pdf\n",
      "     Focused professional targeting challenging assignments in Data Science with an organization of high repute.       Profile Summary      Experienced in Data Science roles across industries.     I am looking for a role where I can leverage my skills and experience  for the betterment of the Organisation and further improvement to  my own learning..    Knowledge of industry best practices and a deep understanding on  how data is extracted, transformed, scrubbed and loaded in Data  storage environments.     Thorough understanding of Data Science tools, techniques and  technologies in Machine Learning, NLP and Deep Learning algorithms   using Python, R SciPy, NumPy, Matplotlib, Tensorflow and Keras.    Thorough  understanding  of  algorithms  like  Regression,  Clustering,NLP Classification, including Time Series forecasting and  Annova methods.     Ability to communicate analytical results in a way that is meaningful  for business stakeholders and provide actionable insights.     Conducted competency review of associates, driven innovation  projects    Resolved all the technical issues arising during the execution of the  project.    Reviewed and edited requirements, specifications, business  processes and recommendations related to the proposed solution.    An effective communicator with the capabilities to relate to people  at any level of business & management.        Core Competencies    Machine learning    Client Relationship Management    Process Optimisation/Cost Reduction    Data Science    Statistics    Python    NLP    Deep learning    tensorflow         Nearly 16 years of extensive experience      Timeline              Organizational Experience    Since May’05  Robert Bosch Engineering and Business Solution, Bengaluru Growth Path:  Senior Engineer  Specialist  Architect   Key Result Areas:       To understand the business use cases from clients and convert them into a well defined problem statement and  explain it to the development team.    Identify and implement use cases which might help the organisation business development.    Shouldering responsibilities for:  o  Leading topics like machine learning and data science  o  Competency management and development of the team    Following up with customers on possible new cooperation and initiating new projects.    Preparing Machine learning prototypes for new type of tasks.    Understanding the business issues and data challenges of client's organization and industry; identifying client  organization's suggesting areas of improvement     Collecting data facts, analyzing them to find root cause of business problem and forwarding the key findings to  the management    To understand the business use cases from clients and convert them into a well defined problem statement and  explain it to the development team.     Directing weekly & daily report creation through in-depth analysis & producing actionable information.    To partner with other departments to solve problems and identify trends and opportunities.     Organizational Projects     1)Title:    Daimler Trucks Asia End to End After Market Supply Chain Solution  Description:       Fuso implemented D2S in May 2015, however there were numerous issues at launch. Issues included inefficient  master data management, low forecast accuracy, incorrect safety stock calculation techniques, poor backorder  management and low overall visibility & transparency. Project requirements included improving supply chain  efficiency, transparency and optimizing stock control.  Technology  Neural Networks, Deep learning, Python, Machine learning, Data Analysis, HIVE, Spark, Azure Cloud Platform  Contribution    Involved in requirement gathering and the concept design phase of the project.    Developed end to end data pipeline using Spark and Scala.    Streaming and processing data through Spark.    Performing analysis for forecasting customer lifetime value, measuring long-term value of campaigns, churn  analysis.    Monetary Analysis, Sentiment Analysis, Navigation Menu Analysis, Net Promoter Score, Spike orders.    Detection Analysis, Causal Impact Analysis.    2000  Since May’05  Robert Bosch  Engineering and  Business Solution,  Bengaluru as  Architect  BE (Mechanical)  from Karnataka  University,  Karnataka  Quantech Global  Services,  Hyderabad as  Junior Engineer  ISRO Satellite Centre,  Airport Road,  Bengaluru as Graduate  Apprentice Trainee  Harita Infoserve  Ltd. (TVS Motors),  Bengaluru as Lead  Engineer  2004-2005  2002-2004  2002    2)Title:  Chatboat for supply chain application  This chatboat is built for automotive aftermarket application. Instead of calling different locations for getting  availability of parts, showrooms and warehouses use this chatboat. This can give info in if particular part is  available on not and if not available how long for the part to arrive to service station.    Technology  NLP, Recurrent neural network  Contribution    Involved in requirement gathering and architecture design.    Building data cleansing pipeline to train a model.    Involved in parameter tuning process for optimal model hyperparameters.    Scripting using python language using NLP and Recurrent neural network algorithms      3)Title:  evaluation and classification of steering housing designs for stress failures  Description:    Steering housings are subjected to different types of loads and combination of these loads can cause failure of  steering housing. Stress values at different points of steering housing for previous variants is considered as past  data . Taking this data of previous housings, task is to predict if any of future housings will fail for given set of  loads.  Technology  Machine Learning, Recurrent neural network  Contribution    Involved in requirement gathering and architecture design.    Creating artificial intelligence recurrent neural network model to establish relationship between different  geometry shapes and failures.    Building data cleansing pipeline to train a model.    Developing statistical models for various predictive methods such as forecasting, classification and    regression.    Involved in parameter tuning process for optimal model hyperparameters.    Generate actionable insights from data and creating presentations and dashboards to make recommendations  for improvement.    Preparing and conducting demonstration of predictive analytics module of BI along with marketing team.       Trainings / Certifications  Attended trainings in:          Attended certifications courses in:      Internet of things(IOT-B)    BES-PE @ Bosch          BMQP  (A  Management  Certification  Program  Conducted at Bosch Global Level)    German Language–A1          Personal Details  Date of Birth: 30th July 1978  Languages Known: X  Address: #10702,Bhuvana Greens Apartments, Off Sarjapur Road, Bengaluru -560035   \n",
      "<DirEntry '20.pdf'>\n",
      "20.pdf\n",
      "                                                                          ➢ A professional with about 20 years of experience in Machine Learning, Web Science, Big Data,  Hadoop Framework, Analytics, Business Intelligence, Full Stack Development, Mobile  Applications, UI Frameworks, Browser & Mobile Platform development with deep insight into E- Commerce and Health Care Industry.  ➢ Thorough understanding of big data technologies like M/R, Pig, Hive, HBase, Scala, Spark, etc.  ➢ In depth knowledge and experience in statistics, machine learning methodologies  ➢ Data Science Professional with experience in all stages of data processing and insights delivery.  ➢ Start-Up Experience working as Vice president for over ~ 2 years, full engineering team (Front  end, backend), IT team for AWS support and managed IT services and delivery responsibility  ➢ Completed Master Degree in Computer Science from IIITB with 80%  (July 2017)  ➢ Worked with various clients (Doha Bank, QIC, IFS), 40K foundation- IOT devices, Openbeds (US),  Verizon, Comverse Lab, Samsung Korea HQ.  ➢ Deep involvement in handling the critical deliverables, benchmarking solutions, driving Key  Metrics, maintaining Productivity and ensuring projects are profitable.  ➢ Knowledge of industry best practices and a deep understanding on how data is extracted,  transformed and handled.  ➢ Expertise in Setting Technology Roadmap and Strategy for Browser on Android & Tizen Platforms  ➢ Responsible for People management and handling team of 50+ engineers {Setting up MBO Goals,  performance Appraisal and Day to day management}  ➢ Expertise in Architecture/Design of various S/W solutions          Development Tools  Expertise  Experience in Years  Python, Machine Learning, Deep  Learning, Statistics, Spark, HBase,   Intermediate  2+ Years  Map/Reduce, Big Data, Hadoop  ecosystem  Expert  5+ Years  PIG, HIVE  Expert  5+ Years  Android, Mobile App development  Expert  8+ Years  Java, C, MYSQL  Expert  10+ years  AGILE, SCRUM based Development  Expert  8+ Years  Design Patterns, Algorithm  Intermediate  3+ Years  Dev-Ops, Dockers, Deployment, CI,  GIT  Intermediate  6+ Years  PHP, E-commerce, Healthcare,  Enterprise Architecture, MVC  Intermediate  3+ Years          ➢ Won Samsung Presidents award, which was given to our team in 2014 among all overseas R&D   ➢ Specially sent on Long Term work to Samsung Telecommunication America-Dallas for 1 year (First  time in the history of SRIB)  Experience Summary  SKILL AND KNOWLEDGE AREAS    RECOGNISIONS    ➢ Received MD’s Super Saver Award in 2009 for developing Dolfin Browser Solution & replacing  royalty solution (NF, Open wave, Opera) saving ~50 Million dollars.  ➢ Awarded the CORE competency, TDI for the last successive 7 years, with special recognition  letter during the tenure in Samsung            •  Working as Vice President(Senior Technical Architect)- at Carmatec IT Solutions Pvt. Ltd –since  May 2017   •  Worked as Head- Delivery and Service Operations for YouGoTag – (Nov 2016 ~ Apr 2017)  •  Associated with Samsung R&D Institute India - Bangalore (SRI-B) July 2001 ~ Oct 2016  -  General Manager   since Mar 2014 {Group Head for Web Team}  -  SDM/GEM    from Apr 2011 ~ Feb 2014  -  Development Manager   from Apr 2007 ~ Mar 2011  -  Development Lead   from Apr 2003 ~ Mar 2007  -  Lead Engineer     from Jul  2001  ~ Mar 2003  •  Senior Software engineer at Motorla India Electronics Ltd– (July 1999 ~ June 2001)  •  Research engineer at C-DOT– (July 1997 ~ June 1999)            Carmatec IT Solutions Pvt. Ltd. (May 2017 – Till Now)    1.  Doha Sooq Ecommerce Platform (July 2017- June 2018)  Doha Sooq is the first and largest online marketplace in Qatar. This project is to revamp the  existing DS platform and setting up a global E-Commerce platform in Big Data environment to  enable performance scalability and cost efficiency using Big Data Technologies implementation.  To store terabytes of log information generated by the ecommerce website and extract  meaningful information out of it. The solution is based on the open source BigData s/w Hadoop.  The data will be stored in Hadoop file system and SPARK/HIVE is used for data transformation.  Worked on Machine Learning with Python.                      Roles & Responsibility  a. Has played the role of a Project Manager, providing overall architectural solution  for the global DohaBank client.  b. Used Spark pipeline for data standardization and data aggregation  c.  Build the model for classifying the products and Recommended suggestions.  d. Developed Customer churn analysis system which led to growth in retention of high  valued potential customers  a. Enabled to run the project in agile delivery model.  b. Played the role of a SME for the end to end delivery of the project.    Technology Stack: Python, Scikit, ML, predictive modelling, Spark, Hive, HDFS, HBase, PIG/Java,  Tableau (presentation layer)    2.  Responsible for the Services Delivery and Operations of Carmatec brands CodeWebber (PHP,  Cake), RailsCarma (Ruby on Rails), ColorCuboid (HTML, UI/UX) and Mobile Apps (Android, iOS)          PROJECT SUMMARY  PROFESSIONAL EXPERIENCE AND ACHIEVEMENTS    YouGoTag Technology Solutions (Nov 2016 – Apr 2017)    3.  Worked as Head- Delivery and Service Operations for YouGoTag  YouGoTag is one of the Technology startup company which is trying to do disruptive in Health  Care Space and planning to bring all the stakeholders such as Hospitals, Doctors, Pharmacist,  Supplier, Manufacturer and ultimately the End Customer to common platform.  To provide predictive analysis in the supply chain for the distributors and Manufactures                     Roles & Responsibility  a. Designed and implemented a scalable technology (Big Data & Hadoop) solution  addressing data inflation and storage issues   b. Data Cleaning, Validation, Enrichment, Analysis and Post Analysis done using Hive  c.  Release Responsibility, Sprint Planning, Features Review, CCB Board owner and  priority finalization along with CTO  d. Schedule and Risk/dependency planning and project execution  e. Overall Infra Responsibility, hardware finalization, Cloud responsibility    Technology Stack: Spark, Java, Map Reduce, HDFS, Hive, Pig, Sqoop, MYSQL    Samsung R&D Institute India - Bangalore (SRI - Bangalore) (July 2001– Oct 2016)    4.  Heading the Web Engine Group & Program Management. (Jan 2014 ~ Oct 2016)    Roles & Responsibility  a. Conceptualized, Developed & Delivered SBrowser APK for Galaxy S6  b. To analyze large amount of data received from varieties of sources, namely mobile  app on different devices to track the behavior of users, classify users and make  appropriate business strategies  c.  Providing analytics by extracting web browsing data for user interactions and their  browsing pattern              Technology Stack: Map Reduce, HDFS, Hive, Pig, Sqoop, MYSQL, Java      5.  Headed Web engine part. Lead the Architecture and Development of Samsung Browser on Web  Engine for Flagship Mobile and Tablet Devices, which is commercialized on Galaxy Note3, S5,  Note4 & Tablet devices across the globe. Responsible for requirement analysis, architecting the  Browser and leading development and commercialization. (April 2013 – Jan 2016)    Roles & Responsibility  a. The Architecture supports common core logic for multiple devices (Mobile/Phablet  & Tablet)  b. Project domain spans from working on webkit browser engine, Chromium Blink  engine, Stock Android Browser, webkit2 browser.  c.  Involved in defining the web strategy and monetization part.   d. Driven Key features/service: Multi Instance, Reader mode, hover support, Custom  Tab  e. Driven the Metrics: JS &HTM5 Benchmark, Graphics Power Savings, Memory and  Performance Optimizations (Page Load, Scroll, Double Tap etc).  f.  Taken the Samsung SBrowser as downloadable APK for Android. It is 50 million  downloads and only app generating revenues through services  https://play.google.com/store/apps/details?id=com.sec.android.app.sbrowser&hl= en)  g. Team ramp-up and skill building      Technology Stack: Android, Core Java, OOPs, Web Engine, HTML5    6.  Headed Browser Part. Developed Samsung Own Browser (Dolfin Browser) for mobile devices.  Have made 3 Major release of Dolfin across all variants (Full touch, hybrid, Full keypad) - Dolfin 0.9  (Jan 2009), Dolfin 1.0 (June 2009), Dolfin 1.5 (Oct 2009), Dolfin 2.0 (May 2010). Managing overall team  of more than 70 engineers (Jan 2008 - Apr 2013)    Roles & Responsibility  a. Created the new project based on the idea proposed by HQ VP (Dream of having  our own browser) with budget approval from Headquarters.  b. Handled the LGPL license issue by providing boot-up time loading & linking of  browser lib with overall phone image on proprietary SHP Phones.  c.  Delivered a hybrid app (Twitter & Facebook apps) on BADA using Web app  framework (list view, scrollable text view and various building blocks etc using Java  Script APIs eg. JQERY )  d. Established a team of 60 personnel for Dolfin Browser in Bangalore for the delivery  of key applications built on Webkit, Java Script, HTML & CSS.  e. Single point contact, prepared SOW for 3rd party Outsourcing Company and set up  ODC for 3 years for Browser support.  f.  Came up with WRT {Web Run Time} Solution which is base for the Tizen Web Apps.  Rapid Team ramp-up and skill building    Technology Stack:  SHP, C, C++, WebKit, OPEN Source Licensing    7.  SHP Platform Enhancement Project (Jan 2007- Dec 2007)  This project is mainly aimed to enhance the SHP Platform Capabilities and   make it ready along  side next generation platforms, so that the rich and vast expertise of Samsung handset  developers can be used in coming up with the next generation handsets in 3G market.      Roles & Responsibility:  a. Worked as Program Manager  b. Responsible for Requirement review & Project Proposal/Plan/Execution Review  c.  Architecture/Design review, Setting the Technology Roadmap  d. Product Benchmarking & Driving the feature definition  e. Verification of Test conformance and Delivery    Technology Stack: SHP, C, Data Structures, OMA compliance, Web Services (SOAP)    8.  Cingular 3G ZX30 Mobile Multimedia Color Handset (Mar 2006 ~ Dec 2006)    Roles & Responsibility:  a. Played the role of Product Lead   b. Requirement review  c.  Schedule and Risk/dependency plan review and project execution review  d. Architecture/Design review  e. Guiding the leads for execution of the project  f.  Customer Interaction  g. Verification of Test conformance and Delivery of REL                    Technology Stack: SHP, C, Data Structures, Config Mgmt (Clearcase)    9.  Liaison Engineer deputed to US for 1 year  (Mar 2005 ~ Feb 2006), handled Verizon Operator    Roles & Responsibility:  a. Complete responsibilities for the Browser activities for all the  Samsung models  in  US  b. Talking with OPERATOR and OPENWAVE, get the preCVT, CVT  done  c.  Responsible for Browser IOT   d. Passing the VZW approval process for all the models  e. Participated in review and finalization of licensing terms and conditions.                 Technology Stack: SHP, C, Data Structures, IOT, Operator compliance     10.  CDMA Products (ACH A790, A795) (Jan 2003 ~ Feb 2005)    Roles & Responsibility:  a. Requirement collection  b. Role of Module Lead, responsible for the development of native   applications  (Phonebook, Planner, Settings and Recent Calls)  c.  Discussion with product planning team for adding new requirements   d. Architecture/Design review, Guiding the team for implementation  e. Train the Team members in UUI architecture.  f.  Verification of Test conformance and Delivery                Technology Stack: UIS Platform, MMI, C, Native App development, Operator Req compliance    11.  Developing Plug-in Applications for the Navi3 Browser (Mar 2002 ~ Dec 2002)    Roles & Responsibility:  a. Role of Team Lead, responsible for Leading the Development, Testing and  Implementation of media player and flash player for the NAVI3 (Samsung’s  proprietary) Browser   b. Requirement collection  c.  Schedule and Risk/dependency planning and project execution  d. Followed all CMM level 5 practices and the project audited for Organization CMM  Level 5 certification.                           Technology Stack: Windows Platform Architecture, Plugin, Flash Player ,C     12.  Developing Embedded Browser(July 2001 ~ Feb 02)    Roles & Responsibility:  a. Team Setup & to develop an embedded browser that will be used in all its products  such as Digital T.V  b. Requirement collection from Samsung Korea   c.  Schedule and Risk/dependency planning and project execution  d. The implementation of this project is done in ‘C’ using VC++ under Window’s 2000  and then ported to the real time PSOS environment                 Technology Stack: Visual Studio, C++, RTOS, C    Motorola India Electronics Limited { R &D Cost center of Motorola US (Libertyville  Chicago)  – Lead Engineer for Motorola iDEN phones (July 1999 –Jun 2001)    13.  CONDOR Product  Development (Jan 2000 ~ June 2001)    Roles & Responsibility:  a. Requirement preparation and Design  b. Involved in gathering the requirements. Design, development, testing and  Integration of “Shortcuts” and “Styles” feature for the CONDOR mobile phone.   c.  Study of ERGO (Motorola’s iDEN phone architecture) and the UIS (User Interface  Services) which is one of the building block in Motorola’s P2K platform  d. Owned the integration activities and integrated with the phone software at the  Customer site (Motorola USA)  14.  Development of SUAPI Layer on the top of ROS (Jul 1999 ~ Dec 1999)    Technology Stack: Mobile Platforms ,MMI, App development framework, C    C-DOT  {Centre for Development of Telematics, Bangalore }  – Research Engineer (July 1997 ~ Jun 1999)    15.  Development of Clear Channel FTP protocol software for the VSAT’s (Jan 1999 ~ June 1999)    Roles & Responsibility:  a. VSATS uses FTP protocol, FTP is implemented using Client-Server model  b. Worked as research Engineer and involved in developing software for connection  setup, data transfer and connection clear objects in the overall FTP software.  c.  UML for Design  16.  Design and Development of Network Traffic Processor (Oct 1997 ~ Dec 1998)  Roles & Responsibility:  a. NTP is a PC with add on cards in the HUB, which acts as a router for the traffic  (DATA) generated by the VSAT connected to it.  b. Implementation of the software for routing the user services across network  c.  Responsible for testing the individual modules, written down test cases for checking  the functionality of various modules.  d. C, Socket Programming, Unix,  HTTP    Technology Stack: C, Socket Programming, Unix, HTTP, UML          1. B.E, Electronics and Communication from Maulana Azad National Institute of Technology with  Grade: A - 81% in 1997 (1993 ~ 1997)  2. Got the Academic Scholar Ship for 2nd, 3rd and 4th Year consecutively during my engineering.   3. Master Degree in Computer Science from IIIT Bangalore in 2017. Got 80% marks, it done Full time  Through Samsung sponsorship program (2014~2017).  Educational Summary  \n",
      "<DirEntry '3+ (2).pdf'>\n",
      "3+ (2).pdf\n",
      "    CAREER OBJECTIVE    A passionate data scientist having knowledge in predictive modelling, data processing, and data  mining algorithms to solve challenging business problems. Strong background in Python and  knowledge of various types of machine learning techniques.      SUMMARY    1. Good understanding of Statistics, Machine learning and deep learning concepts.  2. Hands on experience in python frameworks like scikit-learn ,scipy,numpy  3. Boosting techniques like XGBOOST, PCA.  4. Basic understanding on ML libraries like tensor flow, spark.  5. Data analysis  6. Classification of images using AI convolutional neural network model  7. Data vitalization using MATLAB  TECHNICAL SKILLS    SKill  Technology known  Programming /Scripting  Python,C,Javascript  Tools /IDE  Pycharm,Pyspyder,Jupyter Notebook  Data Science  Machine learning, Data Aritifical Inteiligence,Statistical modelling  ,Natural language Processing, Deep learning ,pandas,scikit- learn,keras,matplotlib,Data virtualization Analysi,tensorflow, spark ,  time series arima model , cnn , RNN , RNN LSTM ,  Operating system  Windows, Linux              PROFESSIONALEXPERIENCE    •  Altimetrik India Private Limited (Sept 2016 –Till date)    Role : System engineer    Project 1 : Banking application monitoring.  Involved in building an AI predictive modelling for monitoring bank application, it will help in checking the health  status and monitoring the interface applications connected with the banking system, it Monitor and raises an  alarm if there is any major issues within the application.  (Python, Random Forest, Convolutional Neural Networks (CNN), Keras, Tensorflow )  Project 2 : Credit and Loan eligiblity score  In this project, we built a model for analyzing the credit score and loan eligibility of the customers based on the  previous transaction and KYC information with cognitive computing technologies with cross validation set and  regression tools while filling the online application.  (Python,classification and regression model , neural networks)    •  Wipro Infotech (Dec 2015- Aug 2016)    Role: Application Engineer    Project : Was involved in designing of chatbot with AI predictive modelling, neural networks  and Machine  learning techniques , The bot was used for conversational banking with quick TAT and helped customers with  their KYC queries and transaction details in chat.    EDUCATION    •  Bachelor of Engineering  - 2014-2015  Tontadarya college of Engineering ,Gadag,Karnataka      •  Pre-University college – 2010  St.Aloysius PU College ,Harihar,Karnataka    EDUCATION    •  Spot Appreciation award – Oct 2017  •  Certificate of Appreciation – Mar 2018  •  Spot Appreciation Award – Feb 2019  \n",
      "<DirEntry '3+.pdf'>\n",
      "3+.pdf\n",
      "      Summary  3+ years total experience in IT industry in which I have 2+ years of in Machine learning which include  predictive modeling, data processing, data mining, Machine Learning algorithms, hands-on experience  leveraging machine learning models to solve challenging business problems and 1 year of experience in  UCCE and CISCO IPT platform.   Experience Summary    •  Involved in Data Preprocessing Techniques for making the data useful for creating Machine  Learning models.  •  Translate product requirements into analytical requirements/specification, design and develop  required functionality.  •  Involved in creating various regression and classification algorithms by using various sklearn  libraries such as Linear Regression, Decision Trees, Naïve Baye’s.  •  Involved in creating a model for predicting the inbound calls for AVIVA, RSA and Barclays using  Kernel SVM  •  Involved in clustering of alarms generated by VoIP devices to reach correct team.      Work Experience    • Vodafone Shared Services   DATA Scientist (May 2016 to till date)    Project 1:  Prediction of inbound calls recording   Technology used: Kernel SVM  Database:  SQL   Summary:All the calls received by the agents are being recorded     and with the help of Kernel SVM we able to predict the       when there is issue with the recording servers.      Project 2:  Clustering of alarms generated by various Networking devices  Technology used:K-Mean Clustering     Database:  SQL  Summary:Alarms generated by various devices are usually assign   with the code and few descriptions. With the help of        K-Mean Clustering the alarm is passed to correct team       for investigation.    •  Vodafone Shared Services   VoIP Specialist (May 2015 to May 2016)  Involve in designing the UCCE call flow, configuring the gateways and implementing the new  changes or new VoIP setups as per the customer requirement.      Technical Skills      Academic Profile    Level  Year of Passing   University / Board  Percentage  Bachelor of Engineering  2014  Nagpur University   68%  HSC  2010  CBSE  75.67%  SSC  2008  CBSE  79.6%        Personal Details    Fathers Name   :  Muniswamy Naidu      Nationality    :  Indian       Gender     :  Male  Date of Birth    :  17-Jun-1991   Languages    :  English and Hindi  Address    : Lalpeth colony DSM 24, Chandrapur , Maharashtra  80% 75% 80% 75% 70% Pandas Numpy Machine Learning Statistics NLP \n",
      "<DirEntry '4+.docx'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944dbd9fb92942aea676e618462ebba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DirEntry '5+ .pdf'>\n",
      "5+ .pdf\n",
      "Data Scientist with Master in Computer Engineering and 3+ years of experience using predictive modeling, data processing, data mining algorithms, hands-on experience leveraging machine learning models to solve challenging business problems. Involved in Python open source community and passionate about deep reinforcement learning. WORK EXPERIENCE Data Scientist Bluebox Technology - 2015 to Present 2015 - Present) • Deep Learning • Classification of Images of the online product buying site, • Artificial Intelligence Convolutional neural network model (CNN) to classify images of different products using TensorFlow program with keras, a high-level • Data cleansing API to build and train models. • Data Modeling • Sentiment Analysis, Political campaign analysis helping for the taking a • Natural Language Processing decision of strategy making for digital marketing, detailed virtualization • Data Virtualization using MATPLOTLIB. • Data Mining • Identifying GIS Functionality using natural language processing, Sophisticated way to define the Google GIS functionality to the • Predictive Modeling customer by using Natural Language Processing, Python NLTK library • Statistical Modeling uses to define the structure of the project. • Data Analysis • To predict the responses of a customer to a specific marketing • Communication Skill offer, using various machine learning algorithms like regression and classification model (KNN, K-Means, Naïve Baise, SVM, etc.) • Team Management Software Tools • Document classification using the classification machine learning Python algorithms (K-means, SVM) Excellent (TensorFlow, Keras, Pandas, Numpy, • CCTC footage analysis, Image classification using Convolutional neural Scipy, Matplotlib, Scikit-learn, NLTK) network model (CNN) identification of the customer detail counts in a R specific period by visual recognition. Good SQL Very Good • Predication of accident on the basis of health history of driver, using MongoDB deep learning concept, artificial neural network to train the model on Good Cassandra the available dataset. Good Java • Recommend system, Good C For the product base website, for the customer support using Recurrent Very Good Neural Network (RNN) on cleaning data with the help of NLTK. C++ Very Good Languages • Face Detection using Microsoft cognitive API. English Proficien • Decide the period of foot fall in a shopping mall based on dates, using Hindi t tensorflow deep learning concepts. Proficien Marathi t Mother Tongue EDUCATION Master of Engineering University of Pune SKILLS MACHINE LEARNING, Data Science, Python, Artificial Intelience, Neural Network, Natural Language Processing, Data Virtulization, Predictive Modelling, Statistical Modeling, Data Analysis, Data Mining, Data Cleaning, Deep Learning, R, SQL, NoSQL, MingoDB, Java, C, C++, Communucation Skill, Team Management (3 years) LINKS https://github.com/AbhijitManepatil ADDITIONAL INFORMATION Skills • Machine Learning • Data Analysis • Artificial intelligence • Predictive modeling • Statistical modeling • Natural Language Processing • Deep learning • Tensorflow • pandas • scikit learn • keras • matplotlib • python • R • C • C++ • SQL • MySQL • Java • MongoDB • Data Cleaning • Data Virtualization • Communication skill • Team Management • \n",
      "<DirEntry '5+.pdf'>\n",
      "5+.pdf\n",
      "Data scientist with three years of experience in predictive modelling, data processing, and data mining algorithms to solve challenging business problems. Strong background in computer programming language, and knowledge of various types of machine learning and natural language processing techniques. Willing to relocate to: Pune, Maharashtra - Hyderabad, Telangana - Bangalore Urban, Karnataka WORK EXPERIENCE DECISION SCIENTIST MU SIGMA -  Bengaluru, Karnataka - 2015 to Present Projects TEXT ANALYTICS | MUFUSION - FOR MU SIGMA ‣ Developed a text analysis engine used by fortune 500 clients. The text analysis engine developed in Python supporting English and Japanese text leverages Sentiment analysis, Theme identification, Categorisation, Named Entity Recognition, Clustering and Word co-occurrence modules to generate insights for decision making. DATA QUALITY AND VALUE ASSESSMENT - FOR A US BASED ASSET MANAGEMENT COMPANY ‣ Designed and developed a comprehensive and versatile Data quality and Value assessment module for a US based asset management company. The module developed on Jupyter notebook with a Python kernel brought down the time of data quality assessment of more than 500 million rows of data from 60hours to 50mins, was compatible with different types of datasets (transaction, health-care, geolocation etc.) and generated 2 reports. It allowed flexibility to the user to tailor the conditions and checks according to the business and assess the quality of data. THE ENERGY INSIGHTS APP - FOR A TOP ENERGY FIRM ‣ Developed a one stop application hosted on Predix platform for a fortune 100 energy firm which helps the business development managers throughout customer engagement journey by leveraging the data available from multiple sources to have richer conversations with customers and help them in taking better decisions to achieve their energy efficiency goals (by generating realistic project roadmap using mixed integer optimisation and linear programming) . Handled the entire backend of the application using python. FINDING DONORS - FOR UDACITY ML BASIC NANO-DEGREE ‣ In this project I applied and evaluated supervised learning techniques like Gaussian Naive Bayes, SVM and Random Forest on data collected for the U.S. census to help CharityML (a fictitious charity organisation) identify people most likely to donate to their cause. Afterwards, I optimised the Random Forest model and presented it as my solution to CharityML. (GitHub) CUSTOMER SEGMENTS - FOR UDACITY ML BASIC NANO-DEGREE ‣ In this project, I analysed a dataset containing data on various customers' annual spending amounts of diverse product categories for internal structure using PCA and Gaussian Mixture Model clustering algorithm to best describe the variation in the different types of customers that a wholesale distributor interacts with to provide insight into how to best structure their delivery service to meet the needs of each customer. (GitHub) Data scientist Mu Sigma - July 2015 to June 2018 EDUCATION BE in Information Technology University of Pune -  Pune, Maharashtra 2015 SKILLS NLP, ML, deep learning, predictive modelling ADDITIONAL INFORMATION Technical Skills Certifications &amp; Awards Python NLP Machine Learning Decision Scientist Data Mining Linux Scala Mu Sigma University - JUN, 2017 Spark GIT IBM doCloud Machine Leaning Nano-degree Udacity - MAY, 2018 Libraries - Data Mining NPTEL - MAY, 2018 NLTK Sk-learn Numpy Impact Award, Mu Sigma - APR, 2018 Mllib Pandas Gensim Spot Award, Mu Sigma - JAN, 2018 spaCy Pattern Pulp \n",
      "<DirEntry '5.pdf'>\n",
      "5.pdf\n",
      "Software Developer/Data Scientist  More than  4 years of experience in Software Development and Project Implementation and out of which 2+years of experience as Data Scientist, Machine Learning  and Deep Learning.Working experience and extensive knowledge in Python, Natural Language Processing with libraries such as Sklearn,Numpy,Pandas,Matplotlib,NLTK,SQL Server, data mining .Platforms and Misc: Anaconda Enterprise Edition, Jupyter Notebook,Spyder IDE,SQL Server  Management Studio, Visual Studio 2017, python IIS, Windows XP/W7/W8Other Skills: All phases of the software development life-cycle (requirements, design,development, testing, release, support), utilizing multiple development methodologies. 06/2017 - Till Date 09/2016 - 04/2017 01/2014 - 08/2016 Software engineer XL SOLUTIONS GROUP Software engineer Hewlett Packard Enterprise Developer Touch idea - 2013 - 2014 - 2014 Bachelor of Engineering, Computer Science   Swami Vivekananda Technical University, Bhilai  Certification Program in Data Science with Deep Learning. AcadgildNIT Hyderabad Diploma in. Net NIT Hyderabad Project Management Data Analysis Data Pre-processing NLP Database Management Model Building Machine Learning Deep Learning Python Numpy Pandas Matplotlib SCIKIT Learn NPL/NLTK Tensorflow Keras SQL Server Summary   Work experience   Education   Projects   Skills   Programming Skills   XL SOLUTIONS GROUP United Educators- Institution Popularity Analysis- The company wanted to get the overviews of feedback given by students and general people before giving them insurance cover. We used NLP to find out that institution is having more positive sentiments or not and provided proper visualization using plots to help  concerned team in taking the decision. ML Crane- Accessories and parts Requirement Prediction System- The company had many service stations across country for service of cranes, and it was difficult for them to maintain supply of all parts across all service centers as they were having different demands to organize the supply they wanted to have predicted model that can predict if that which parts will be needed in a particular region and they used to provide those parts in that region. We got many data related to climate, industrial uses and other related information and using which we prepared our model. For this we tested many ML algorithms and then found decision tree and random forest were having similar output so we decided to put decision tree as the it needed less computation time and less computational resources. Technology Used- Pandas,Numpy , PCA ,Matplotlib ,Random Forest Classifiers,SQL Server 2012. HEWLETT PACKARD ENTERPRISE. VFS Global  - Visa Approval Prediction- One of our client VFS wanted to have a prediction system which would classify applications in 3 categories based on chances of approval high, medium and low based on which they used to either process the application to concerned country’s o�ice, this was helpful mainly for student and work visas as their approval depends on trend mostly. We got all previous data like the course detail ,highest qualification, year of stay etc. to build the model and using that we built model. In this case we got one of the best accuracy using decision tree and so finalized the model. Touch Idea . My HRWIZARD - This project mainly deals with providing efficient and accurate payroll services to companies. Companies ranging from a single employee to thousands of employees can use these services for the effective management of employee payroll services. One of the main features of this project is report generation based on wide variety of base reports. It is useful in payroll processing, maintenance of time and attendance, HR services, Maintenance of insurance and access to workers compensation etc. This system provides a broad range of time keeping that allow employers to effectively track employee hours.   Each feature is offered to assist in conveniently organizing and quantifying an employee's work day. Key features include Job costing, Automated overtime Calculations, Holiday tracking and payment, Online time-card editing, Daily auto email report etc. TAF  Route Management of a Bicycle Riding Event - The objective is to manage the whole route of a bicycle riding event. It has different modules like registration of riders as well as volunteers, creation and management of route map, task assignment to all, tracking the riders’ locations and showing in the map, helping and assisting the riders etc. Guide the team member to understand the requirement and allocate the work accordingly. Communicate with client to understand the planning of projects and provide them progress reports of each modules. Gather complete requirements of the project from user To analyse the requirement and prepare best suited database structure design for the project. Create the database, tables, function and stored procedure for the project. Work on the code and develop the application and provide support to system team fro go live process. “ONLINE PC BUILDER” is customized for configure PC Online  this project can make easy to configure and purchase pc online, and provide online ordering environment for your personal computer users. Project is completed in Three Tire architecture. In this project we used ASP.NET, technology for making a web application, jQuery for validation, Bootstrap for responsive web page, and MySQL Database for backend in this project developed in two modules which is based on User and Admin module. Worked as Project Leader with work in designing and requirement analysis phase of Software Development Life Cycle (SDLC). We followed the waterfall model. Along with this helped in programming in different modules. Animated website design. Responsibilities   Educational Credentials   \n",
      "<DirEntry '6+.pdf'>\n",
      "6+.pdf\n",
      " I am an applied computer vision data scientist who have had experience in a leading a bunch of other data scientists. I have used my leadership and applied deep learning skills to successfully execute various computer vision projects. Highly skilled in applied deep learning - Computer Vision. Good understanding of various computer vision techniques like classification, bounding box classification and regression(object detection),pixel wise prediction(segmentation), sequence classification with LSTMs (video classification). Good Interpreter of business requirements into technical terms and vice versa. Excellent in use case identification from business requirements.  Achievements include execution of various computer vision projects like building character identification,fashion style guide recommender, Fashion attribute predictor, activity detection, image search engine. My work got accepted in AI & Deep Learning Conference | GTC 2018 | NVIDIA. I am looking for a role where i can leverage my skills and experience for the betterment of the Organisation and further improvement to my own learning. I am a regular AI/ML blogger. I am a firm believer in Andre NG's view of democratising AI. I pass on my knowledge to the community through various blogs. To understand the business use cases from clients and convert them into a well defined problem statement and explain it to the development team. To identify data sets required to develop predictive models for solving internal and external business problems To fill data gap by gathering data , designing annotation portal  and conducting  data annotation by human annotators. To explore data sets and identify data transformation and data quality needs for targeted applications To develop algorithms and predictive models to derive insights and business value from data To provide leadership and mentorship to other members of the team. Identify and implement use cases which might help the organisation business development To interpret results and produce actionable business insights that lead to measurable business and consumer experience performance improvements To Operationalize, publish, and monitor successful models to shape business and data science strategy To partner with other departments to solve problems and identify trends and opportunities To define and develop the program for metrics creation, data collection, modeling, and reporting the operational performance To work cross-functionally to define problem statements, collect data, build analytical models and make recommendations. To routinely communicate metrics, progresses and other key indicators to leadership. To lead and support various ad hoc projects, as needed, in support of Organizations’s Business strategy. 2017 - 2018 Lead Data Scientist - Computer Vision Cogknit Semantics core python numpy pandas tensorflow caffe openCV Machine Learning Deep Learning Spark RDD,DataFrame : Used for Data transformation MapReduce : Used as a data processing engine  R : Experimental works mainly on structured data Summary   Responsibilities   Work experience   Skills   Others    https://www.visualcv.com/abhaymise 2016 - 2017 2015 - 2016 2013 - 2015 Leads a team of 15 members including data scientists,product engineers and UI engineers. Data Scientist Cogknit Semantics First member of the computer vision team in the organisation Data Engineer Cogknit Semantics Senior Research Analyst Edureka 2009 - 2013 June 15, 2016 - June 15, 2016 2017 - 2017 2016 - 2016 Bachelor of Engineering,Computer Science visvesvaraya technological university Machine Learning by Stanford University on Coursera with 96.1% Stanford A machine learning course by one of the pioneer of Artificial Intelligence Deep Learning Specialisation Deeplearning.ai It carries 5 deep learning courses with focus on Neural Net , CNN , LSTM and Bi-LSTMs Attended cs231n CNN for visual Recognition course Stanford Attended and completed all the assignments of the course A Poster on \"Domain Adaption of Image Caption Model for Video Descriptions\" was accepted at AI & Deep Learning Conference | GTC 2018 | NVIDIA Multiple blogs has been identified as best reads across  various  ML/AI forums 2018 - present 2018 - present Men Style Guide creation  Cogknit Semantics Recommend best matching attire for men given a particular attire. The recommended attire is created on the fly with an inspiration from an automated style guide. The automated style guide  brings the trend factor by following feeds of the fashion celebrities and accordingly create the combination for recommendation. Built with pandas, numpy, tensorflow, keras Metadata Extraction from a media content Cogknit Semantics Education   Achievement   Projects    https://www.visualcv.com/abhaymise 2017 - 2018 2017 - 2017 2016 - 2017 2016 - 2017 2016 - 2017 2016 - 2016 2017 - 2018 Extract attributes  like scene count,scene boundaries of each scene, scene identification , Character identification , Character's facial features identification , activity detection , objectionable activity flagging , speaker identification and close caption generation across all scenes. The extracted attributes will be exposed micro service for further business monetisation. Built with tensorflow, Kaldi, Keras,OpenCV   Face and Voice based authenticated wallet Cogknit Semantics An authentication system which can be provide multi modal authentication with signals from face and voice . The authentication can be attached against any payment system . In our case we attached it against a payment system which was running over blockchain. Automated transcript generation from advertisement video for e-retail Cogknit Semantics The project aims in solving a business case the e-retailers website should accessible to a visually impaired person. Aim is to create a transcripts having visual and audio information about the given video. This transcript would contain complete information including all actions , emotions , clothing attributes and spoken sentences. This transcript would be used by the video owners in explaining their products to visually impaired person. Built with tensorflow, Kaldi, Keras,OpenCV   Scene Retrieval using Tensorflow and Opencv Cogknit Semantics This system allows you to retrieve and play a video from the scene that you desire. Built using openCV as means of IO,Inception-v3 CNN encoder from tensorflow to extract features of the video. Image search using tensorflow Cogknit Semantics This system has been trained to recognise categories of the query image and then to retrieve the most closest match under the identified category as a search result. Built with tensorflow  CNN classifier, encoder and vectorised search system. Automated image curation system using tensorflow Cogknit Semantics This system helps in accelerating the cleaning process of the training data of image classifiers. It brings out all the junks from the training data and provides a system to delete/move from the categories. Built with tensorflow CNN feature extractors and vectorised information retrieval technique. Auto correction of e-Commerce catalogue using caffe Cogknit Semantics This system tries to find the mis-placed item under a category in an e-commerce catalogue.Once it finds the misplaced item it reports it to the admin and then suggest the correct category under which the product should actually be placed. Built with caffe CNN classifier.  Automated Attendance system Cogknit Semantics This marks an employee presence in office by detecting his/her face at the entry of the office.  https://www.visualcv.com/abhaymise 2017 - 2017 2015 - 2016 Built with tensorflow CNN classifier and openCV. Auto tagging of visual contents for indexing using tensorflow Cogknit Semantics This system automatically generates a textual description of an image. This also marks the image with multiple tags as per the objects detected in the image. Captioning system built with CNN-LSTM encoder-decoder system. Meta tag generation is built using Faster-RCNN network. Recommendation System for smart learning using numpy Cogknit Semantics Recommends learning contents to an user based on his and his peer activities.The learning process of like minded learners is collaborated to suggest  new and useful contents to an user. Collaborative filtering of user and item attributes has been used .  https://www.visualcv.com/abhaymise \n",
      "<DirEntry '7+.pdf'>\n",
      "7+.pdf\n",
      "Data Scientist  Seeking a challenging and successful career in Data Science and related technologies like predictive modelling, data cleaning, data processing, data retraining and data mining algorithms to solve challenging business problems. I also have good  background in Python and knowledge of various types of machine learning techniques including 3 years of hands-on in predictive modelling To understand the business use cases from clients and convert them into a well defined problem statement. To identify data sets required to develop predictive models for solving internal and external business problems. To fill data gap by gathering data , designing annotation portal and conducting data annotation by human annotators. To explore data sets and identify data transformation and data quality needs for targeted applications To develop algorithms and predictive models to derive insights and business value from data To work cross-functionally to define problem statements, collect data, build analytical models and make recommendations. To routinely communicate metrics, progresses and other key indicators to leadership. 2018 - present 2014 - 2018 2011 - 2014 2009 - 2011 2005 - 2009 Senior Associate DXC Technology Lead Administrator Wipro Senior Software Engineer Oracle Associate Consultant Genisys Software Associate Software Engineer Tata Consultancy Services Amazon Web Services Deep Learning Machine Learning Matplotlib Pandas Numpy Python Python : Experimental works mainly on structured data. Software Tools : Jupiter, Anaconda, Spyder, Keras, Tensorflow Others: AWS Amazon Web Services Solution Certified Associate Summary   Responsiblities   Work experience   Skills   Others   Certifications    https://www.visualcv.com/nizams/ Bachelor of Engineering in Computer Science Sri Jayachamarajendra College of Engineering Pre University Certificate -12th Panchagiri Pre-university College Secondary School Leaving Certificate - 10th std Panchagiri Practising High School APR 2018 - PRESENT To predict the traffic on a new mode of transport DXC Technologies The client is considering making an investment in a new form of transportation - Deusche Bahn Rail. Deusche Bahn uses Jet propulsion technology to run rails and move people at a high speed! While Deusche Bahn has mastered the technology,  the investment would only make sense, if they can get more than 1 Million monthly users with in next 18 months.  (Python, Scikit-learn, Univariate time-series, ARIMA) 2016 - 2018 To predict the category of different human activities Wipro Technologies In this project, Client wanted us  to predict human activity (1-Walking, 2-Walking upstairs, 3- Walking downstairs, 4-Sitting, 5-Standing or 6-Laying) by using the smartphone’s sensors. (Python, Random Forest, Convolutional Neural Networks(CNN), Keras, Tensorflow ) 2015 - 2016 To predict if a loan will get approved or not Wipro Technologies Company wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have given a problem to identify the customers segments, those are eligible for loan amount so that they can specifically target these customers. (Python Programming, Scikit-learn, Machine Learning, Logistic Regression, Random Forest Classification, Decision Tree Classification, Dimension Reduction, K-Fold Cross validation )  Date Of Birth : 12 Dec, 1982 Father's Name : Shamsuddin GR Languages Known : English, Hindi,Kannada,Telugu Permanent Address : No.16B, 8th B Main Road, BTM Layout First stage, Bangalore - 560029 Education   Projects           Personal Details    https://www.visualcv.com/nizams/ \n",
      "<DirEntry '8+.docx'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17194843d3234f66a34a0752cc7c53b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DirEntry '8+.pdf'>\n",
      "8+.pdf\n",
      "RESUME      Summary:  Data Scientist with Master in Computer Engineering 7+ Years of Experience in Software Development  and Web Analytics Implementation and 3+ years of Experience Using Predictive Modelling, Data  Processing, DataMining Algorithms,Natural language processing(NLP), hands-on experience  leveraging machine learning, Deep Learning Models to Solve Challenging Business Problems.    Job Responsibility:  •  Achievement-Driven Professional withaRelevant Experience of 3+ Years.  •  Deep involvement in handling the Critical Deliverables, Benchmarking Solutions, Driving  Key Metrics, Maintaining Productivity and ensuring Projects are Profitable.  •  Experience in Statistics, Machine Learning & NLP and Python Methodologies.  •  Experience in Visualization Tools Like Tableau Software, GoogleAnalytics, Adobe  Analytics  •  To understand the business use cases from clients and convert them into a well-defined  problem statement and explain it to the development team.  •  To Develop Algorithms and Predictive Models to Drive Insights and Business Values from  Data  •  To identify data sets required to develop predictive models for solving internal and external  business problems  •  Identify and implement use cases which might help the organization business  development To interpret results and produce actionable business insights that   •  lead to measurable business and consumer experience performance improvements    •  Experience in building applications with Artificial Intelligence, Machine Learning, Deep  Learning, Recurrent Neural Network, Computervision, NLP and Python.  •  Worked on Deployment and optimization of various computer vision, Machine learning and  NLP solution on web based application, Azure platform using kubernetes services and  Raspberry pi.   •  Designing the neural networks using Tensor flow for various internal projects within the  company and working on Chatbots using NLP    Technical Skills:  Skill  Technology worked on  Domain  Marketing Analytics  Programming/Scripting  Python, JS  Tools/IDE  Pycharm, Pyspyder, Jupyter  Notebook, Eclipse  Cloud  Google Cloud,Azure,AWS,GAIA ( Pivotal Cloud Foundry )  Machine learning   Machine Learning,Data Analysis, Artificial intelligence, Natural  Language Processing, Pandas, Scikit learn, Matplotlib, Python, Data  Cleaning  Deep Learning/Computer  Tensorflow, keras, CNN, Faster CNN, RNN, RNN – LSTM, Vgg16,  vision   Resnet-50, Mobilenet, SSD, Harcascade, Tensorflow JS   Project Methodology  Agile SCRUM  Operating Systems  Windows, Ubuntu  Distribution  Cloudera   Hardware  Nvidia Tesla,Raspberry Pi 3b+   Version Control  GIT, BIT BUCKET  Data Base  SQL,My SQL    Skils and Knowledge Areas:      Development Tools  Expertise  Experience in Years  Python Programming  Expert  3+ Years  Machine Learning  Expert  3+ Years  NLP – Natural Language Processing Expert  3+ Years  Data Visualization  Expert  3+ Years  MYSQL  Expert  3+ Years  AGILE, SCRUM Based Development  Expert  3+ Years  Deep Learning  Intermediate  1+ Years  Big Data  Intermediate  1+ Years  Computer Vision  Intermediate  1+ Years      Tools and Libraries Used:    Numpy  Pandas  Stats Models  Scipy  Seaborn  Matplotlib  Scikit-learn  Jupyter Notebooks  Google Colab  NLTK  Tensorflow  Keras  Open CV  TextBlob  Tweepy  Gensim  Spacy  BeautifulSoup    Educational Summary:     MBA from NIBM (National Institute of Business Management), Chennai with 84.19% (2017-2018)  Tamil Nadu    BCA from Bishop Heber College (Autonomous) Trichy with 64.17% (2004-2007) Tamil Nadu.    Professional Experience:    AssociatedwithZinavo Technologies-Bangalore2012 to Till Now  Zinavo Technologies, an ISO 9001-2008 certified company, extending its services in Software & IT  Development Company in Bangalore, India   Data Scientist From March 2016 to Till Now-3+ Years   Digital Analytics Consultant From April 2014-March -2016-2 Year   Digital Marketing Engineer From April 2012 –March-2014- 2 Years    Accountabilities:    Core Python,Numpy,Pandas,Matplotlib,SCIKIT Learn, Tensor flow, Tableau    Selecting features, building and optimizing classifiers using machine learning techniques    Data mining using state-of-the-art methods    Extending company’s data with third party sources of information when needed    Enhancing data collection procedures to include information that is relevant for building  analytic systems    Processing, cleansing, and verifying the integrity of data used for analysis    Doing ad-hoc analysis and presenting results in a clear manner    Creating automated anomaly detection systems and constant tracking of its performance    Projects Summary:      Client Name  Project Title  Technology  Roles  Durations  Zinavo  Customer Sales  Predictions&Chat  Bots  Development  Google Add Click  Predictions  Keywords  Analysis  Python   Machine Learning  Data Visualization  Microsoft Luis  Dialog flow  NLP  Google Cloud  PredictiveModelling  Data Scientist  On Going  Altius Hospitals  Analysis of the  Medical Records  of individual’s  Lung Capacity  Python   Machine Learning  Data Visualization  Matplotlib  Data Scientist  On Going  Tshirt Loot  Sentiment  Analytics  Python  Naïve Bayes Algorithm  NLP  Data Scientist  2017-2018  Tripath  Logistics  Transportation  Supply Chain    Management  System    Python   Machine Learning  Data Visualization  Matplotlib  Data Scientist  On Going  PRO FX   Market Basket  Analysis  Python   Machine Learning  Data Visualization  Matplotlib  Data Scientist  2017-2018  Magical Nest  Interior Designs  Pvt.Ltd.  Ecommerce  Products  Recommendation  System  Python   Machine Learning  Data Visualization  Matplotlib  Data Scientist  2017-2018  POC  Classification  Problem     Python   Keras, Pandas, Numpy  Data Scientist  2+ Years  POC  Object Detection  Deep Learning  Data Scientist  2+ Years  POC  Human Activity  Recognition  Algorithms : Logistic  Regression,  Data Scientist  2+ Years  using Machine  Learning  KNeighborsClassifier,  RandomForestClassifier             Declaration:  I hereby declare that the above information is true and correct to the best of my knowledge and belief.  PLACE: Bangalore                Yours Faithfully  DATE:                   (R.Nazar)   THANK YOU    \n",
      "<DirEntry 'freasher .pdf'>\n",
      "freasher .pdf\n",
      "RESUME    Email    Mobile   LinkedIn  GitHub     Objective:    To work in a challenging atmosphere by exhibiting my skills with at most sincerity and dedicated  smart work for the growth of esteemed organization along with mine.    Technical Skills:    Operating Systems  Windows 7/10, Linux.  Programming  Languages  Python,C,HTML  Knowledge In  Technology    Data Analysis with Python    Data Visualization with Python    Machine Learning with Python(Linear Regression ,Logistic  Regression,KNN, k Means Clustering, PCA,  Decision Tree, Random Forest, Bayesian)    Deep Learning with tensorflow and keras.    Depth Knowledge in Probability and Statistics     Ms word    WordPress  Tools      Pyspyder    Jupyter Notebook    Eclipse    Projects:    Human Activity Recognition using Machine Learning  In this project Use machine learning to recognise various activities by  taking the activity   recognition data set. The dataset includes sensor readings of 30 different individuals   and the   type of activity they were recorded for. This data was extracted from Kaggle to classify various   activities.  Algorithms  : Logistic Regression, KNeighborsClassifier, RandomForestClassifier      Classification Problem  This Project is to identify the image of Person by certain number of images of two persons by  using Convolutional Neural Network Algorithm.  Technologies : Keras, Pandas, Numpy    TRAZADO-Wireless Device Tracking System (Main Project):     This project is track any wireless device even when they turned off. Using an inbuilt chips and  GPS attached to the battery. The Micro controller get activated and processed using the signals  from the nearby stations and able to track location.    E-JWELL-An Android app (Mini Project):   This is android app is for women safety and protection. Set a small device and it interconnect  with mobile app. If anybody attacking, the device connects with mobile app and find the  location and sent alert message to mobile phone and nearest police station.  Educational Details    Examination  School/ College  Board/ University   Year of  Passing  Percentage   B.Tech –  Computer  Science  Ahalia School of Engineering  and Technology Palakkad  (Kerala)  Calicut University  2016  72.3%  HSE  GVGHSS, Chittur, Palakkad  (Kerala)  State Board of HSE,  Kerala  2012  85.67%  SSLC  VMHS, Vadavannur,  Palakkad,Kerala  State Board of  Education, Kerala  2010  95.5%    Achievements      Attended Two days Workshop on Python conducted by ACCENT TECHNO SOFT (ATS)  Coimbatore.    Attended the seminar on “Cyber Security”.    Participated in the Workshop on HADOOP BIGDATA at Interface 2K15.  Personal Details    Sex      : Female  Date of Birth    : 08/02/1994  Marital Status   : Married  Nationality    Languages Known  : English, Malayalam, Tamil     Address    : Indian \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from docx2pdf import convert\n",
    "import sys, fitz\n",
    "directory = 'sample-resume'\n",
    "\n",
    "\n",
    "for filename in os.scandir(directory):\n",
    "   \n",
    "    print(filename)\n",
    "    #----------------------------------\n",
    "    if(filename.path.endswith(\".docx\")):\n",
    "        path = pathlib.Path(filename)\n",
    "       \n",
    "        converttopdf(filename)\n",
    "        file_path_new = os.path.splitext(filename.path)[0]\n",
    "        file_name_new = Path(file_path_new).stem\n",
    "        filename1=f' {file_name_new}.pdf'\n",
    "        filename=pathlib.Path(filename1)\n",
    "       \n",
    "        \n",
    "          \n",
    "    #-------------------------------------------------------\n",
    "    if(filename.is_file()):\n",
    "        #print(filename.name)\n",
    "        frame =filename.path\n",
    "        with fitz.open(filename.path) as docs:\n",
    "            \n",
    "       \n",
    "           tx = \"\"\n",
    "           for page in docs:\n",
    "            tx = tx +str(page.get_text())\n",
    "            \n",
    "        text = \" \".join(tx.split('\\n')) \n",
    "            \n",
    "        print(text)  \n",
    "            \n",
    "    file_path = os.path.splitext(frame)[0]\n",
    "    file_name = Path(file_path).stem\n",
    "    #print(file_path)\n",
    "    #print(file_name)\n",
    "    out_file=open('sample-resume-textformat/'+file_name,\"w\",encoding=\"utf-8\")\n",
    "    out_file.write(text)\n",
    "       \n",
    "    \n",
    "    \n",
    "out_file.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting Docx file into pdf file\n",
    "def converttopdf(filename):\n",
    "    #print(\"in function\")\n",
    "    new_filename =  Path(filename).stem\n",
    "    \n",
    "    convert(f\"sample-resume/{filename.name}\", f\"sample-resume/{new_filename}.pdf\")\n",
    "    os.unlink(filename)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
